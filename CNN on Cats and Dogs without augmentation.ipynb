{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40450aa7",
   "metadata": {},
   "source": [
    "This is an exercise to learn Convolutional Neural Networks using TensorFlow. The following code blocks helps us classify kaggle cats and dogs dataset. The folllowing is the procedure followed: \n",
    "1. Get your data into a local or a temp directory\n",
    "2. Visualize a few images to validate that they are correctly loaded\n",
    "3. Divide the dataset into training and validation sets\n",
    "4. Build your custom ConvNet \n",
    "5. Check the sumary of your model and parametes to train\n",
    "6. Compile the model to specify the optimizer, loss function and evaluation metrics\n",
    "7. Create the Image Data generator to generate your images\n",
    "8. Finally fit the model to data generated in the previous step\n",
    "9. Test your images on unseen data \n",
    "\n",
    "The dataset was downloaded from the following website \"\"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88e07274",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6628a975",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This block unzips the dataset in the tmp folder\n",
    "import zipfile\n",
    "local_zip = 'C:/Users/Shubham Kamble/tmp/kagglecatsanddogs_3367a.zip'\n",
    "zip_ref   = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('C:/Users/Shubham Kamble/tmp')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4524b905",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This block makes a directory for two classes cats and dogs in the tmp folder\n",
    "import os \n",
    "try:\n",
    "    os.mkdir('C:/Users/Shubham Kamble/tmp/cats-vs-dogs')\n",
    "    local_dir = 'C:/Users/Shubham Kamble/tmp/cats-vs-dogs'\n",
    "    classes = ['cats','dogs']\n",
    "    \n",
    "    for class_name in classes:\n",
    "        os.makedirs(os.path.join(local_dir, \"training\", class_name))\n",
    "        os.makedirs(os.path.join(local_dir, \"testing\", class_name))\n",
    "\n",
    "except OSError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8956f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This block helps to stop training when a desired accuracy is reached using callbacks \n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('accuracy')>0.5):\n",
    "            print(\"\\nReached 50% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85e9a286",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This blocks defines a function to split the dataset into training and testing sets\n",
    "import random\n",
    "from shutil import copyfile\n",
    "def split(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n",
    "    files = [] \n",
    "    for f in os.listdir(SOURCE):\n",
    "        file = SOURCE + f\n",
    "        if os.path.getsize(file)>0:\n",
    "            files.append(f)\n",
    "    \n",
    "    files = random.sample(files, len(files))\n",
    "    split_point = len(files) * SPLIT_SIZE\n",
    "\n",
    "    for i, f in enumerate(files):\n",
    "        source = os.path.join(SOURCE, f)\n",
    "        if i < split_point:\n",
    "            destination = os.path.join(TRAINING, f)\n",
    "        else:\n",
    "            destination = os.path.join(TESTING, f)\n",
    "        \n",
    "        copyfile(source, destination)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2111929e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This block uses the split(..) function to split both classes into training and testing datasets respectively\n",
    "CAT_SOURCE_DIR = \"C:/Users/Shubham Kamble/tmp/PetImages/Cat/\"\n",
    "TRAINING_CATS_DIR = \"C:/Users/Shubham Kamble/tmp/cats-vs-dogs/training/cats/\"\n",
    "TESTING_CATS_DIR = \"C:/Users/Shubham Kamble/tmp/cats-vs-dogs/testing/cats/\"\n",
    "DOG_SOURCE_DIR = \"C:/Users/Shubham Kamble/tmp/PetImages/Dog/\"\n",
    "TRAINING_DOGS_DIR = \"C:/Users/Shubham Kamble/tmp/cats-vs-dogs/training/dogs/\"\n",
    "TESTING_DOGS_DIR = \"C:/Users/Shubham Kamble/tmp/cats-vs-dogs/testing/dogs/\"\n",
    "\n",
    "split_size = .9\n",
    "split(CAT_SOURCE_DIR, TRAINING_CATS_DIR, TESTING_CATS_DIR, split_size)\n",
    "split(DOG_SOURCE_DIR, TRAINING_DOGS_DIR, TESTING_DOGS_DIR, split_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbcefd05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11250\n",
      "11250\n",
      "1250\n",
      "1250\n"
     ]
    }
   ],
   "source": [
    "#This block checks whether the split was a success\n",
    "print(len(os.listdir('C:/Users/Shubham Kamble/tmp/cats-vs-dogs/training/cats/')))\n",
    "print(len(os.listdir('C:/Users/Shubham Kamble/tmp/cats-vs-dogs/training/dogs/')))\n",
    "print(len(os.listdir('C:/Users/Shubham Kamble/tmp/cats-vs-dogs/testing/cats/')))\n",
    "print(len(os.listdir('C:/Users/Shubham Kamble/tmp/cats-vs-dogs/testing/dogs/')))\n",
    "\n",
    "# Expected output:\n",
    "# 11250\n",
    "# 11250\n",
    "# 1250\n",
    "# 1250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b58f8f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 148, 148, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 74, 74, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 72, 72, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 36, 36, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 34, 34, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 17, 17, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 18496)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               9470464   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 9,494,561\n",
      "Trainable params: 9,494,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#This block helps build a simple ConvNet and compile it by specifying the optimizer, \n",
    "#loss and evaluation metrics\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    \n",
    "])\n",
    "\n",
    "model.compile(optimizer=RMSprop(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "880e5a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22498 images belonging to 2 classes.\n",
      "Found 2500 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "TRAINING_DIR = \"C:/Users/Shubham Kamble/tmp/cats-vs-dogs/training/\" \n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255.) \n",
    "train_generator = train_datagen.flow_from_directory(TRAINING_DIR, \n",
    "                                                    batch_size=100,\n",
    "                                                    class_mode='binary',\n",
    "                                                    target_size=(150, 150))\n",
    "\n",
    "VALIDATION_DIR = \"C:/Users/Shubham Kamble/tmp/cats-vs-dogs/testing/\"\n",
    "validation_datagen = ImageDataGenerator(rescale=1.0/255.) \n",
    "validation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR, \n",
    "                                                              batch_size=100,\n",
    "                                                              class_mode='binary',\n",
    "                                                              target_size=(150, 150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada2c135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 14/225 [>.............................] - ETA: 4:19 - loss: 1.4766 - accuracy: 0.5107"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\PIL\\TiffImagePlugin.py:793: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - ETA: 0s - loss: 0.6968 - accuracy: 0.6332"
     ]
    }
   ],
   "source": [
    "callbacks = myCallback()\n",
    "\n",
    "history = model.fit(train_generator,\n",
    "                              epochs=10,\n",
    "                              verbose=1,\n",
    "                              validation_data=validation_generator,\n",
    "                              callbacks = [callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788ff83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This block helps us to get the evaluation metrics and graph it to check for overfitting\n",
    "acc=history.history['accuracy']\n",
    "val_acc=history.history['val_accuracy']\n",
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "\n",
    "epochs=range(len(acc)) # Get number of epochs\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#Plots the training and validation accuracy per epoch\n",
    "plt.plot(epochs, acc, 'r', \"Training Accuracy\")\n",
    "plt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.figure()\n",
    "\n",
    "#Plot training and validation loss per epoch\n",
    "plt.plot(epochs, loss, 'r', \"Training Loss\")\n",
    "plt.plot(epochs, val_loss, 'b', \"Validation Loss\")\n",
    "plt.figure()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef89391",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This block helps to upload a real-time image and check whether our model predicts it correctly or not\n",
    "# import numpy as np\n",
    "# from google.colab import files\n",
    "# from keras.preprocessing import image\n",
    "\n",
    "# uploaded = files.upload()\n",
    "\n",
    "# for fn in uploaded.keys():\n",
    "#     # predicting images\n",
    "#     path = '/content/' + fn\n",
    "#     img = image.load_img(path, target_size=(150, 150))\n",
    "#     x = image.img_to_array(img)\n",
    "#     x = np.expand_dims(x, axis=0)\n",
    "\n",
    "#     images = np.vstack([x])\n",
    "#     classes = model.predict(images, batch_size=10)\n",
    "#     print(classes[0])\n",
    "#     if classes[0]>0.5:\n",
    "#         print(fn + \" is a dog\")\n",
    "#     else:\n",
    "#         print(fn + \" is a cat\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
